{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99975aa8-314a-4012-89e5-e2e0ba34c730",
   "metadata": {},
   "source": [
    "### Multivariate Linear Regression (다변량 선형 회귀)\n",
    "- 하나의 종속변수와 여러 독립변수 사이의 관계를 분석하는 기법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2abee9e7-beeb-4e7a-b9e9-604b083a2a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     TV  Radio  Newspaper  Sales\n",
       "0             1  230.1   37.8       69.2   22.1\n",
       "1             2   44.5   39.3       45.1   10.4\n",
       "2             3   17.2   45.9       69.3    9.3\n",
       "3             4  151.5   41.3       58.5   18.5\n",
       "4             5  180.8   10.8       58.4   12.9\n",
       "..          ...    ...    ...        ...    ...\n",
       "195         196   38.2    3.7       13.8    7.6\n",
       "196         197   94.2    4.9        8.1    9.7\n",
       "197         198  177.0    9.3        6.4   12.8\n",
       "198         199  283.6   42.0       66.2   25.5\n",
       "199         200  232.1    8.6        8.7   13.4\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a_df = pd.read_csv('../datasets/advertising.csv')\n",
    "a_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7acad0be-9f65-416d-95c4-7ff08c823394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  Radio  Newspaper  Sales\n",
       "0    230.1   37.8       69.2   22.1\n",
       "1     44.5   39.3       45.1   10.4\n",
       "2     17.2   45.9       69.3    9.3\n",
       "3    151.5   41.3       58.5   18.5\n",
       "4    180.8   10.8       58.4   12.9\n",
       "..     ...    ...        ...    ...\n",
       "195   38.2    3.7       13.8    7.6\n",
       "196   94.2    4.9        8.1    9.7\n",
       "197  177.0    9.3        6.4   12.8\n",
       "198  283.6   42.0       66.2   25.5\n",
       "199  232.1    8.6        8.7   13.4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_a_df = a_df.drop(labels=['Unnamed: 0'], axis=1)\n",
    "pre_a_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b7b3a04-adb3-4370-a314-f488ea3fb710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100/1000: W1: 0.0616,W2: 0.1041,W3: 0.0580, b: 0.0025, loss: 7.4172\n",
      " 200/1000: W1: 0.0561,W2: 0.1499,W3: 0.0570, b: 0.0038, loss: 5.1731\n",
      " 300/1000: W1: 0.0543,W2: 0.1762,W3: 0.0482, b: 0.0048, loss: 4.3777\n",
      " 400/1000: W1: 0.0535,W2: 0.1929,W3: 0.0402, b: 0.0057, loss: 4.0271\n",
      " 500/1000: W1: 0.0531,W2: 0.2039,W3: 0.0342, b: 0.0066, loss: 3.8664\n",
      " 600/1000: W1: 0.0529,W2: 0.2113,W3: 0.0300, b: 0.0074, loss: 3.7921\n",
      " 700/1000: W1: 0.0528,W2: 0.2162,W3: 0.0271, b: 0.0082, loss: 3.7576\n",
      " 800/1000: W1: 0.0527,W2: 0.2196,W3: 0.0251, b: 0.0090, loss: 3.7414\n",
      " 900/1000: W1: 0.0526,W2: 0.2219,W3: 0.0238, b: 0.0098, loss: 3.7337\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(124)\n",
    "\n",
    "features, targets = pre_a_df.iloc[:, :-1], pre_a_df.iloc[:, -1]\n",
    "\n",
    "features\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(features, targets, test_size=0.2, random_state=124)\n",
    "\n",
    "X_train1 = torch.FloatTensor(X_train.TV.values).view(-1,1)\n",
    "X_train2 = torch.FloatTensor(X_train.Radio.values).view(-1,1)\n",
    "X_train3 = torch.FloatTensor(X_train.Newspaper.values).view(-1,1)\n",
    "y_train = torch.FloatTensor(y_train.values).view(-1,1)\n",
    "\n",
    "X_test1 = torch.FloatTensor(X_test.TV.values).view(-1,1)\n",
    "X_test2 = torch.FloatTensor(X_test.Radio.values).view(-1,1)\n",
    "X_test3 = torch.FloatTensor(X_test.Newspaper.values).view(-1,1)\n",
    "y_test = torch.FloatTensor(y_test.values).view(-1,1)\n",
    "\n",
    "W1 = torch.zeros(1, requires_grad=True)\n",
    "W2 = torch.zeros(1, requires_grad=True)\n",
    "W3 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "optimizer = SGD([W1, W2, W3, b], lr=1e-5)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    H = W1 * X_train1 + W2 * X_train2 + W3 * X_train3 + b\n",
    "    loss = torch.mean((y_train - H) ** 2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('{:4d}/{}: W1: {:.4f},W2: {:.4f},W3: {:.4f}, b: {:.4f}, loss: {:.4f}'\\\n",
    "              .format(epoch, epochs, W1.item(), W2.item(), W3.item(),b.item(), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "701045dc-f864-4510-9c48-110262c3e18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.411946773529053\n"
     ]
    }
   ],
   "source": [
    "H = 0.0525 * X_test1 + 0.2234 * X_test2 + 0.0228 * X_test3 + 0.0106\n",
    "loss = torch.mean((y_test - H) **2)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ba62b32-ace7-44ca-a8d4-4c6512c8c08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100/1000: W1: 0.0616, W2: 0.1041, W3: 0.0580, b: 0.0025, loss: 7.4172\n",
      " 200/1000: W1: 0.0561, W2: 0.1499, W3: 0.0570, b: 0.0038, loss: 5.1731\n",
      " 300/1000: W1: 0.0543, W2: 0.1762, W3: 0.0482, b: 0.0048, loss: 4.3777\n",
      " 400/1000: W1: 0.0535, W2: 0.1929, W3: 0.0402, b: 0.0057, loss: 4.0271\n",
      " 500/1000: W1: 0.0531, W2: 0.2039, W3: 0.0342, b: 0.0066, loss: 3.8664\n",
      " 600/1000: W1: 0.0529, W2: 0.2113, W3: 0.0300, b: 0.0074, loss: 3.7921\n",
      " 700/1000: W1: 0.0528, W2: 0.2162, W3: 0.0271, b: 0.0082, loss: 3.7576\n",
      " 800/1000: W1: 0.0527, W2: 0.2196, W3: 0.0251, b: 0.0090, loss: 3.7414\n",
      " 900/1000: W1: 0.0526, W2: 0.2219, W3: 0.0238, b: 0.0098, loss: 3.7337\n",
      "1000/1000: W1: 0.0525, W2: 0.2234, W3: 0.0228, b: 0.0106, loss: 3.7298\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(124)\n",
    "\n",
    "features, targets = pre_a_df.iloc[:, :-1], pre_a_df.iloc[:, -1]\n",
    "\n",
    "features\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(features, targets, test_size=0.2, random_state=124)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train.values)\n",
    "y_train = torch.FloatTensor(y_train.values).view(-1,1)\n",
    "\n",
    "X_test = torch.FloatTensor(X_test.values)\n",
    "y_test = torch.FloatTensor(y_test.values).view(-1,1)\n",
    "\n",
    "# 행렬을 맞추기 위해서 (내적을 위해서) 차원을 맞춰준다\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "optimizer = SGD([W, b], lr=1e-5)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    # 선형결합의 수 (내적 곱셈)\n",
    "    H = X_train.matmul(W) + b\n",
    "    loss = torch.mean((y_train - H) ** 2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('{:4d}/{}: W1: {:.4f}, W2: {:.4f}, W3: {:.4f}, b: {:.4f}, loss: {:.4f}'\\\n",
    "              .format(epoch, epochs, W[0].item(), W[1].item(), W[2].item(),b.item(), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e43ea89d-3020-49a3-93ed-92a5ac7b03d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100/1000: W1: 0.0525, W2: 0.2234, W3: 0.0228, b: 0.0106, loss: 15.2955\n",
      " 200/1000: W1: 0.0525, W2: 0.2234, W3: 0.0228, b: 0.0106, loss: 6.5948\n",
      " 300/1000: W1: 0.0525, W2: 0.2234, W3: 0.0228, b: 0.0106, loss: 4.8940\n",
      " 400/1000: W1: 0.0525, W2: 0.2234, W3: 0.0228, b: 0.0106, loss: 4.2642\n",
      " 500/1000: W1: 0.0525, W2: 0.2234, W3: 0.0228, b: 0.0106, loss: 3.9841\n",
      " 600/1000: W1: 0.0525, W2: 0.2234, W3: 0.0228, b: 0.0106, loss: 3.8555\n",
      " 700/1000: W1: 0.0525, W2: 0.2234, W3: 0.0228, b: 0.0106, loss: 3.7960\n",
      " 800/1000: W1: 0.0525, W2: 0.2234, W3: 0.0228, b: 0.0106, loss: 3.7683\n",
      " 900/1000: W1: 0.0525, W2: 0.2234, W3: 0.0228, b: 0.0106, loss: 3.7553\n",
      "1000/1000: W1: 0.0525, W2: 0.2234, W3: 0.0228, b: 0.0106, loss: 3.7489\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch.optim import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(124)\n",
    "\n",
    "features, targets = pre_a_df.iloc[:, :-1], pre_a_df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(features, targets, test_size=0.2, random_state=124)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train.values)\n",
    "y_train = torch.FloatTensor(y_train.values).view(-1,1)\n",
    "\n",
    "X_test = torch.FloatTensor(X_test.values)\n",
    "y_test = torch.FloatTensor(y_test.values).view(-1,1)\n",
    "\n",
    "# 행렬을 맞추기 위해서 (내적을 위해서) 차원을 맞춰준다\n",
    "l_r = Linear(3, 1)\n",
    "\n",
    "optimizer = SGD(l_r.parameters(), lr=1e-5)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    # 선형결합의 수 (내적 곱셈)\n",
    "    H = l_r(X_train) + b\n",
    "    loss = mse_loss(y_train, H)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('{:4d}/{}: ', end='')\\\n",
    "              .format(epoch, epochs, W[0].item(), W[1].item(), W[2].item(),b.item(), loss.item()))\n",
    "\n",
    "    for i, w in enumerate(list(l_r.parameters())[0][0]):\n",
    "        print('W{}: {:.4f}', end=''.format(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d90efe3-bd9e-442b-881e-636bd961cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.411946773529053\n"
     ]
    }
   ],
   "source": [
    "H = 0.0525 * X_test1 + 0.2234 * X_test2 + 0.0228 * X_test3 + 0.0106\n",
    "loss = torch.mean((y_test - H) **2)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f00a5d3-81a1-4565-879e-a3f2f0d95716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Linear\n",
    "\n",
    "class LinearRegressionModel(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1729c053-72cd-4e69-999e-46b82de27360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch.optim import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(124)\n",
    "\n",
    "features, targets = pre_a_df.iloc[:, :-1], pre_a_df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(features, targets, test_size=0.2, random_state=124)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train.values)\n",
    "y_train = torch.FloatTensor(y_train.values).view(-1,1)\n",
    "\n",
    "X_test = torch.FloatTensor(X_test.values)\n",
    "y_test = torch.FloatTensor(y_test.values).view(-1,1)\n",
    "\n",
    "# 행렬을 맞추기 위해서 (내적을 위해서) 차원을 맞춰준다 (사전 정의된 linearRegressionModel에서 차원 변경 완료)\n",
    "l_r = LinearRegressionModel()\n",
    "\n",
    "optimizer = SGD(l_r.parameters(), lr=1e-5)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    # 선형결합의 수 (내적 곱셈)\n",
    "    H = l_r(X_train) + b\n",
    "    loss = mse_loss(y_train, H)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('{:4d}/{}: '\\\n",
    "              .format(epoch, epochs), end='')\n",
    "        for i, w in enumerate(list(l_r.parameters())[0][0]):\n",
    "            print('W{}: {:.4f}, '.format(i + 1, w.item()), end='')\n",
    "        print('b: {:.4f}, loss: {:.4f}'.format(list(l_r.parameters())[1].item(), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ae4b2-cd32-490d-89fd-d46663417492",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 0.0525 * X_test1 + 0.2234 * X_test2 + 0.0228 * X_test3 + 0.0106\n",
    "loss = torch.mean((y_test - H) **2)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f0fe8d-a5a0-4e99-a77c-a43736010b40",
   "metadata": {},
   "source": [
    "### Sklearn - LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d1a4b51-125f-44f4-afb2-97781eb90853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "features, targets = pre_a_df.iloc[:, :-1], pre_a_df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(features, targets, test_size=0.2, random_state=321)\n",
    "\n",
    "l_r = LinearRegression()\n",
    "l_r.fit(X_train, y_train)\n",
    "print('W: {:.4f}, b: {:.4f}'.format(l_r.coef_[0], l_r.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3922b317-1223-4202-92cc-45241602706c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss: 2.8103, RMSE loss: 1.6764\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "prediction = l_r.predict(X_test)\n",
    "print('MSE loss: {:.4f}, RMSE loss: {:.4f}'\\\n",
    "      .format(mean_squared_error(y_test, prediction), np.sqrt(mean_squared_error(y_test, prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc946d-43c2-445c-b7cf-df4aab477852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모든 가중치 출력\n",
    "# for feature, coef in zip(features.columns, l_r.coef_):\n",
    "#     print(f'{feature}: {coef:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2cee36-e8a7-4353-bf97-f9225b4c6c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4460f793-7ea7-44f0-97b6-8b87e64b6a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fafcb6-24d5-459a-9147-112f61f50a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
